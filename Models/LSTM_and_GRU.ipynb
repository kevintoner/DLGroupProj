{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40c6503",
   "metadata": {
    "id": "d40c6503"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8eb609b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eb609b3",
    "outputId": "eb01fc97-7e17-4837-d8e9-f4affa775484"
   },
   "outputs": [],
   "source": [
    "# Mount onto Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('drive')\n",
    "\n",
    "# # Move to Google Drive and create folder\n",
    "# %cd /content/drive/My\\ Drive/Deep_Learning_Project_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfad0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_name in [\"GRU_Graphs\", \"LSTM_Graphs\"]:\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(folder_name + \" Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e240ac10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e240ac10",
    "outputId": "3adc5158-0749-4878-f672-e11f3cd84d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully fetched train and test datasets\n"
     ]
    }
   ],
   "source": [
    "# Fetch the train/test data from the csv file\n",
    "train_csv = 'Datasets/train_data.csv'\n",
    "test_csv = 'Datasets/test_data.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_csv, index_col = 'Date')\n",
    "df_test = pd.read_csv(test_csv, index_col = 'Date')\n",
    "\n",
    "print('successfully fetched train and test datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BDpsNVyQJFAv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "BDpsNVyQJFAv",
    "outputId": "a311352d-65c1-44b7-86c1-76cc5801b01e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>^NDXT_Close</th>\n",
       "      <th>QTEC_Close</th>\n",
       "      <th>^SP500-45_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.917821</td>\n",
       "      <td>-0.907476</td>\n",
       "      <td>-0.917195</td>\n",
       "      <td>-0.914544</td>\n",
       "      <td>-0.914544</td>\n",
       "      <td>2.194687</td>\n",
       "      <td>-0.837896</td>\n",
       "      <td>-0.840978</td>\n",
       "      <td>-0.832003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.912616</td>\n",
       "      <td>-0.894926</td>\n",
       "      <td>-0.904533</td>\n",
       "      <td>-0.887362</td>\n",
       "      <td>-0.887362</td>\n",
       "      <td>2.272368</td>\n",
       "      <td>-0.816892</td>\n",
       "      <td>-0.819800</td>\n",
       "      <td>-0.808579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.889194</td>\n",
       "      <td>-0.888814</td>\n",
       "      <td>-0.887463</td>\n",
       "      <td>-0.880544</td>\n",
       "      <td>-0.880544</td>\n",
       "      <td>1.836779</td>\n",
       "      <td>-0.822993</td>\n",
       "      <td>-0.824687</td>\n",
       "      <td>-0.817037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.880190</td>\n",
       "      <td>-0.884733</td>\n",
       "      <td>-0.880309</td>\n",
       "      <td>-0.886807</td>\n",
       "      <td>-0.886807</td>\n",
       "      <td>0.928411</td>\n",
       "      <td>-0.820503</td>\n",
       "      <td>-0.820343</td>\n",
       "      <td>-0.813875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.884076</td>\n",
       "      <td>-0.887523</td>\n",
       "      <td>-0.882058</td>\n",
       "      <td>-0.883476</td>\n",
       "      <td>-0.883476</td>\n",
       "      <td>1.197357</td>\n",
       "      <td>-0.817606</td>\n",
       "      <td>-0.815999</td>\n",
       "      <td>-0.807513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close    Volume  ^NDXT_Close  \\\n",
       "0 -0.917821 -0.907476 -0.917195 -0.914544  -0.914544  2.194687    -0.837896   \n",
       "1 -0.912616 -0.894926 -0.904533 -0.887362  -0.887362  2.272368    -0.816892   \n",
       "2 -0.889194 -0.888814 -0.887463 -0.880544  -0.880544  1.836779    -0.822993   \n",
       "3 -0.880190 -0.884733 -0.880309 -0.886807  -0.886807  0.928411    -0.820503   \n",
       "4 -0.884076 -0.887523 -0.882058 -0.883476  -0.883476  1.197357    -0.817606   \n",
       "\n",
       "   QTEC_Close  ^SP500-45_Close  \n",
       "0   -0.840978        -0.832003  \n",
       "1   -0.819800        -0.808579  \n",
       "2   -0.824687        -0.817037  \n",
       "3   -0.820343        -0.813875  \n",
       "4   -0.815999        -0.807513  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise data using mean and SD from train_df\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training dataset\n",
    "scaler.fit(df_train)\n",
    "scaled_train_df = pd.DataFrame(columns=df_train.columns)\n",
    "scaled_train_df[scaled_train_df.columns] = scaler.transform(df_train)\n",
    "scaled_train_df\n",
    "\n",
    "# Test dataset is scaled later as it requires for the end of the \n",
    "# training dataset to be prepended to it before scaling.\n",
    "\n",
    "scaled_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zL7CItYxpxFB",
   "metadata": {
    "id": "zL7CItYxpxFB"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "input_size = len(df_train.columns)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_outputs = 1 # Regression problem\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "model_name = 'GRU_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791283f0",
   "metadata": {
    "id": "791283f0"
   },
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class StockDataSet (Dataset):\n",
    "    \n",
    "    def __init__(self,raw_data,sequence_length):        \n",
    "        self.target = torch.Tensor([np.array(raw_data['Close']).astype(np.float32)]).T\n",
    "        self.features = torch.Tensor(np.array(raw_data).astype(np.float32))\n",
    "        self.seq_len = sequence_length\n",
    "    \n",
    "    def __getitem__(self,index): # allows us to index our instance\n",
    "        \n",
    "        input_feat = self.features[index:index+ self.seq_len]\n",
    "        label = self.target[index +self.seq_len]  \n",
    "        return input_feat,label \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)- self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24aceb4",
   "metadata": {
    "id": "b24aceb4"
   },
   "outputs": [],
   "source": [
    "# Define LSTM class\n",
    "class LSTM_NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,num_outputs):\n",
    "        super(LSTM_NN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "       \n",
    "         # When set batch_first = True input sample dims shoud be:\n",
    "         #(batch_size, seq_len , input_size)\n",
    "        \n",
    "        if model_name == \"GRU_model\":\n",
    "            # For GRU (Gated Recurrent Unit)\n",
    "            self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states and memory states:\n",
    "        h0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(device) \n",
    "        # Note:  x.size()[0] = batch_size\n",
    "\n",
    "#         \n",
    "        # or:\n",
    "    \n",
    "        if model_name == \"GRU_model\":\n",
    "            output, _ = self.gru(x, h0)  \n",
    "        else:\n",
    "            output, _ = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # output: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # The output of the last cell is of our concern\n",
    "        output = output[:, -1, :] # output.size : (batch_size, hidden_size)\n",
    "        \n",
    "        output = self.fc(output) # output.size: (batch_size , 1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c767dc6e",
   "metadata": {
    "id": "c767dc6e"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs, model_name):\n",
    "    os.makedirs('checkpoint',exist_ok = True)\n",
    "    checkpoint_path=f'{model_name}.pth'\n",
    "    n_total_steps = len(train_loader)\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    \n",
    "    # Record the number of times since improvement for early stopping\n",
    "    num_since_impr = 0\n",
    "    stop_after = 50 # Stop after 5 epochs if no improvements to loss \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0 \n",
    "        counter = 0\n",
    "\n",
    "        for i, (features, labels) in enumerate(train_loader):  \n",
    "\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_running_loss+=loss.item() * len(labels)\n",
    "            counter += len(labels)\n",
    "        \n",
    "        train_loss = (train_running_loss/counter)    \n",
    "        print (f\" Epoch [{epoch+1}/{epochs}],\"\n",
    "                   +  f\" Training loss: {train_loss :.3f}\")\n",
    " \n",
    "        test_loss, _ , _ = test_model(model,test_loader,criterion)\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        if epoch == 0:\n",
    "          least_test_loss = test_loss \n",
    "        \n",
    "        elif epoch > 0 and test_loss_list[-1] < least_test_loss:\n",
    "          least_test_loss = test_loss_list[-1]\n",
    "          torch.save(model.state_dict(), 'checkpoint'+'/'+ checkpoint_path)\n",
    "            #print(test_loss_list[-1])\n",
    "          # Reset counter\n",
    "          num_since_impr = 0\n",
    "        else:\n",
    "            num_since_impr +=1\n",
    "        # If no\n",
    "        if num_since_impr >= stop_after:\n",
    "            print(\"EARLY STOPPING\")\n",
    "#             return model, train_loss_list, test_loss_list  \n",
    "            \n",
    "    return model, train_loss_list, test_loss_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12cdc5d",
   "metadata": {
    "id": "d12cdc5d"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_running_loss = 0\n",
    "    counter = 0\n",
    "    predicted = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (features, labels) in test_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()*len(labels)\n",
    "            counter += len(labels)\n",
    "            predicted.append(outputs.detach().cpu().numpy())\n",
    "            true_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "        test_loss = (test_running_loss/counter)\n",
    "        print(f' Test loss of the network: {test_loss:.3f} ')\n",
    "    \n",
    "    return test_loss, predicted, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tRn4S_t9pPuM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRn4S_t9pPuM",
    "outputId": "2ed817c3-b854-4fef-95cb-f55ab709a6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using cuda\")\n",
    "seed = 2022\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc9a8b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dc9a8b0",
    "outputId": "965e4c4d-5b1b-4a8a-9640-c270e98ef752",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENCE LENGTH IS: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-304291d2117e>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  self.target = torch.Tensor([np.array(raw_data['Close']).astype(np.float32)]).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch [1/1], Training loss: 0.028\n",
      " Test loss of the network: 3.529 \n",
      " Test loss of the network: 3.669 \n",
      "The RMSE value is: 32.90625\n",
      "The RMSE value is: 26.969566\n",
      "The RMSE value is: 23.67039\n",
      "The RMSE value is: 23.264822\n",
      "The RMSE value is: 21.047108\n",
      "The RMSE value is: 23.354504\n",
      "The RMSE value is: 550.0472\n",
      "SEQUENCE LENGTH IS: 10\n",
      " Epoch [1/1], Training loss: 0.031\n",
      " Test loss of the network: 3.685 \n",
      " Test loss of the network: 3.463 \n",
      "The RMSE value is: 36.032112\n",
      "The RMSE value is: 29.238943\n",
      "The RMSE value is: 25.700165\n",
      "The RMSE value is: 24.426968\n",
      "The RMSE value is: 22.251534\n",
      "The RMSE value is: 23.139328\n",
      "The RMSE value is: 534.36206\n",
      "SEQUENCE LENGTH IS: 20\n",
      " Epoch [1/1], Training loss: 0.028\n",
      " Test loss of the network: 3.333 \n",
      " Test loss of the network: 3.429 \n",
      "The RMSE value is: 35.907494\n",
      "The RMSE value is: 29.149239\n",
      "The RMSE value is: 25.621\n",
      "The RMSE value is: 24.37124\n",
      "The RMSE value is: 22.193316\n",
      "The RMSE value is: 23.12657\n",
      "The RMSE value is: 531.7441\n",
      "SEQUENCE LENGTH IS: 30\n",
      " Epoch [1/1], Training loss: 0.038\n",
      " Test loss of the network: 3.881 \n",
      " Test loss of the network: 3.422 \n",
      "The RMSE value is: 35.899563\n",
      "The RMSE value is: 29.143576\n",
      "The RMSE value is: 25.615929\n",
      "The RMSE value is: 24.367645\n",
      "The RMSE value is: 22.189362\n",
      "The RMSE value is: 23.126398\n",
      "The RMSE value is: 531.1792\n",
      "SEQUENCE LENGTH IS: 50\n",
      " Epoch [1/1], Training loss: 0.034\n",
      " Test loss of the network: 3.893 \n",
      " Test loss of the network: 3.418 \n",
      "The RMSE value is: 35.899025\n",
      "The RMSE value is: 29.143179\n",
      "The RMSE value is: 25.61558\n",
      "The RMSE value is: 24.367393\n",
      "The RMSE value is: 22.189085\n",
      "The RMSE value is: 23.126429\n",
      "The RMSE value is: 530.86884\n",
      "SEQUENCE LENGTH IS: 70\n",
      " Epoch [1/1], Training loss: 0.029\n",
      " Test loss of the network: 3.336 \n",
      " Test loss of the network: 3.417 \n",
      "The RMSE value is: 35.89903\n",
      "The RMSE value is: 29.143185\n",
      "The RMSE value is: 25.615583\n",
      "The RMSE value is: 24.367393\n",
      "The RMSE value is: 22.189089\n",
      "The RMSE value is: 23.126429\n",
      "The RMSE value is: 530.79974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len_list = [5, 10, 20, 30, 50, 70]\n",
    "\n",
    "epochs=1\n",
    "\n",
    "# Go through each of the sequence lengths\n",
    "for seq_len in seq_len_list: \n",
    "    start_time = time.time()\n",
    "    print(\"SEQUENCE LENGTH IS:\", str(seq_len))\n",
    "    \n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    # = = = = = = = = = = = = = = = = Set up Data Loaders = = = = = = = = = = = = = = = = \n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    scaled_df_test = pd.DataFrame(columns=df_test.columns)\n",
    "    # Prepend end of training dataset to the start of test dataset and then scale it\n",
    "    new_df_test = pd.concat([df_train[-seq_len:].copy(), df_test])\n",
    "    scaled_df_test[scaled_df_test.columns] = scaler.transform(new_df_test)\n",
    "    \n",
    "    # Make a copy of the data\n",
    "    raw_train_data = scaled_train_df.copy()\n",
    "    raw_test_data = scaled_df_test.copy()\n",
    "\n",
    "    # Instantiate train and test dataset objects\n",
    "    train_dataset = StockDataSet(raw_train_data, seq_len) \n",
    "    test_dataset = StockDataSet(raw_test_data, seq_len)\n",
    "    \n",
    "    # Define train and test loaders\n",
    "    train_loader = DataLoader(dataset = train_dataset,\n",
    "                             batch_size = batch_size,\n",
    "                             num_workers = 2,\n",
    "                             shuffle = False) # shuffle= True??\n",
    "\n",
    "    test_loader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size = batch_size,\n",
    "                             num_workers = 2,\n",
    "                             shuffle = False)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    #  = = = = = = = = = = = = = Set Up and Train the Model = = = = = = = = = = = = = = =\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    \n",
    "    # Instantiate LSTM model object\n",
    "    lstm_model = LSTM_NN(input_size, hidden_size, num_layers, num_outputs).to(device)\n",
    "\n",
    "    # Instantiate loss and optimizer objects:\n",
    "    criterion = nn.MSELoss() # Not cross entropy because regression problem\n",
    "    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate) \n",
    "    \n",
    "    # RUN THE MODEL\n",
    "    model, train_loss_list, test_loss_list = train_model(lstm_model, train_loader, test_loader, criterion, optimizer, epochs, model_name)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    #  = = = = = = = = = = = = = = = = Test the Model = = = = = = = = = = = = = = = = = =\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    \n",
    "    # Predicted vs true stock prices\n",
    "    best_model = LSTM_NN(input_size, hidden_size, num_layers, num_outputs).to(device)\n",
    "\n",
    "    # Load best model weights\n",
    "    best_model.load_state_dict(torch.load('checkpoint'+'/'+ model_name + '.pth'))\n",
    "    _ , predicted, true_labels = test_model(best_model, test_loader, criterion)\n",
    "\n",
    "    predicted = np.concatenate(predicted)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    # = = = = = = = = = = = = = = = = = Save Graph Plot = = = = = = = = = = = = = = = = =\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    \n",
    "    # Revert back to normal\n",
    "    pred_unscaled = predicted*np.sqrt(scaler.var_[3])+ scaler.mean_[3]\n",
    "    true_unscaled = true_labels*np.sqrt(scaler.var_[3])+ scaler.mean_[3]\n",
    "    x_day = range(len(predicted))\n",
    "    plt.plot(x_day, pred_unscaled, label='Predicted')\n",
    "    plt.plot(x_day, true_unscaled, label='True')\n",
    "\n",
    "    plt.title('Predicted vs True Stock Prices',fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Day', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Stock Price',fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    if model_name == \"GRU_model\":\n",
    "        plt.savefig(\"GRU_Graphs/GRU_Graph_\" + str(seq_len) + \".png\")\n",
    "    else:\n",
    "        plt.savefig(\"LSTM_Graphs/LSTM_Graph_\" + str(seq_len) + \".png\")\n",
    "    \n",
    "    # Clear plot\n",
    "    plt.clf()\n",
    "    \n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "    # = = = = = = = = = = = = = = = = = Save Metrics = = = = = = = = = = = = = = = = = =\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    \n",
    "    # Get result for each number of forecast steps\n",
    "    for fore_step in [10,20,30,40,50,60,753]:\n",
    "        rmse = mean_squared_error(true_unscaled[:fore_step], pred_unscaled[:fore_step], squared=False)\n",
    "    \n",
    "        # Record rmse values in csv file\n",
    "        print(\"The RMSE value is:\", rmse)\n",
    "        with open(model_name + \".csv\", \"a\") as res_file:\n",
    "            res_file.write(str(seq_len) + \", \" + str(fore_step)+ \", \" + str(rmse)+\"\\n\") # + \",epoch_num:\"+str(num_epochs)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d1963a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "1d1963a4",
    "outputId": "d9f5efad-d4a4-446f-880a-cb706b55100d"
   },
   "outputs": [],
   "source": [
    "# # Predicted vs true stock prices\n",
    "# best_model = LSTM_NN(input_size, hidden_size, num_layers, num_outputs).to(device)\n",
    "\n",
    "# # Load best model weights\n",
    "# best_model.load_state_dict(torch.load('checkpoint'+'/'+ model_name + '.pth'))\n",
    "# _ , predicted, true_labels = test_model(best_model, test_loader, criterion)\n",
    "\n",
    "# predicted = np.concatenate(predicted)\n",
    "# true_labels = np.concatenate(true_labels)\n",
    "\n",
    "# # Revert back to normal\n",
    "# pred_unscaled = predicted*np.sqrt(scaler.var_[3])+ scaler.mean_[3]\n",
    "# true_unscaled = true_labels*np.sqrt(scaler.var_[3])+ scaler.mean_[3]\n",
    "# x_day= range(len(predicted))\n",
    "# plt.plot(x_day, pred_unscaled, label='predicted')\n",
    "# plt.plot(x_day, true_unscaled, label='True')\n",
    "\n",
    "    \n",
    "# plt.title('Predicted vs True Stock Prices',fontsize=14, fontweight='bold')\n",
    "# plt.xlabel('Day', fontsize=14, fontweight='bold')\n",
    "# plt.ylabel('Stock Price',fontsize=14, fontweight='bold')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e99bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
